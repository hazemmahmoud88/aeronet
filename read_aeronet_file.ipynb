{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2><font color=\"red\" size=\"+3\">Reading Aeronet Data Files with Pandas</font></h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Suppress warning messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print('Using pandas version ',pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Use seaborn style defaults and set the default figure size\n",
    "sns.set(rc={'figure.figsize':(11, 4)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data\n",
    "\n",
    "- The file contains 6 metadata rows (to be skipped).\n",
    "- Values are separated by commas (`,`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/astg606/py_materials/master/aeronet/\"\n",
    "filename = \"19930101_20190209_Dakar.ONEILL_lev20\"\n",
    "\n",
    "#filename = \"19930101_20190209_GSFC.lev20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aero_df = pd.read_csv(url+filename, skiprows=6, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aero_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete last column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aero_df.columns[len(aero_df.columns)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aero_df.drop(aero_df.columns[len(aero_df.columns)-1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aero_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aero_df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aero_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the first two columns into a `datetime` object\n",
    "\n",
    "- We combine the first two columns (Date and Time) into one unique `Datetime` object that will now be the column of indices. This will allows us to easily manipualte the data.\n",
    "- Set all `-999` as missing values (`NaN`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda x: datetime.datetime.strptime(x, '%d:%m:%Y %H:%M:%S')\n",
    "aero_df = pd.read_csv(url+filename, skiprows=6, na_values=-999,\n",
    "                      parse_dates={'datetime': [0, 1]}, \n",
    "                      date_parser=dateparse, index_col=0, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aero_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop any rows that are all `NaN` and any cols that are all `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aero_df = aero_df.dropna(axis=1, how='all').dropna(axis=0, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aero_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select four columns to form a new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(aero_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = aero_df[['Total_AOD_500nm[tau_a]',\n",
    "                  'Fine_Mode_AOD_500nm[tau_f]',\n",
    "                  'Coarse_Mode_AOD_500nm[tau_c]',\n",
    "                  'FineModeFraction_500nm[eta]']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop column or row with all `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.dropna(axis=1, how='all').dropna(axis=0, how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns = ['aot', 'aotc', 'faotf', 'faotc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the daily means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_dm = new_df.resample(\"D\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_dm = new_df_dm.dropna(axis=1, how='all').dropna(axis=0, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform various plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_dm.plot(linewidth=0.5, subplots=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_dm['2012':'2018'].plot(linewidth=0.9, subplots=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_dm['2012':'2018'].plot.area(linewidth=0, subplots=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "df = new_df_dm['2012':'2018']\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, ncols=1, sharex=True)\n",
    "\n",
    "ax[0].plot(df.aot, marker='.', \n",
    "           markersize=2, color='0.6', linestyle='None', label='aot')\n",
    "#ax[0].xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel('Year')\n",
    "\n",
    "ax[1].plot(df.aotc, marker='.', \n",
    "           markersize=2, color='0.6', linestyle='None', label='aotc')\n",
    "#ax[1].xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel('Year')\n",
    "\n",
    "ax[2].plot(df.faotf, marker='.', \n",
    "           markersize=2, color='0.6', linestyle='None', label='faotf')\n",
    "#ax[2].xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax[2].legend()\n",
    "ax[2].set_xlabel('Year')\n",
    "\n",
    "ax[3].plot(df.faotc, marker='.', \n",
    "           markersize=2, color='0.6', linestyle='None', label='faotc')\n",
    "#ax[3].xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax[3].legend()\n",
    "ax[3].set_xlabel('Year')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the annual means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_am = new_df.resample(\"A\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_am.plot(style='b--', subplots=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the values for 2017 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2017 = new_df[new_df.index.year == 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2017.plot(style='b--', subplots=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the values for April 2017 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df201704 = df2017[df2017.index.month == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df201704 = new_df[new_df.index.year == 2017 & new_df.index.month == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df201704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df201704.plot(kind='scatter', x='aot', y='aotc');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average daily values of April 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df201704_dm = df201704.resample(\"D\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df201704_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df201704_dm.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSFC - Beijing - Kanpur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_Beijing = url+'19930101_20210102_Beijing.lev20'\n",
    "fname_GSFC = url+'19930101_20210102_GSFC.lev20'\n",
    "fname_Kanpur = url+'19930101_20210102_Kanpur.lev20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda x: datetime.datetime.strptime(x, '%d:%m:%Y %H:%M:%S')\n",
    "df = pd.read_csv(fname_Beijing, skiprows=6, na_values=-999,\n",
    "                      parse_dates={'datetime': [0, 1]}, \n",
    "                      date_parser=dateparse, index_col=0, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_cols = ['Day_of_Year', 'AOD_675nm', 'AOD_440nm', \n",
    "            '440-675_Angstrom_Exponent', \n",
    "             'Site_Latitude(Degrees)', 'Site_Longitude(Degrees)',\n",
    "             'Site_Elevation(m)']\n",
    "\n",
    "new_cols = ['DoY', 'A675', 'A440', 'Alpha', 'Lat', 'Lon', 'Alt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Beijing = df[old_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Beijing.columns = new_cols\n",
    "df_Beijing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Beijing['A550'] = df_Beijing['A675']*((675.0/550.0))**df_Beijing['Alpha']\n",
    "df_Beijing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_B = \"Beijing\"\n",
    "lat_B = df_Beijing['Lat'][0]\n",
    "lon_B = df_Beijing['Lon'][0]\n",
    "\n",
    "print(lat_B, lon_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Beijing[df_Beijing.index.year == 2010].plot(x='DoY', \n",
    "                                               y='A550', \n",
    "                                               color='k',\n",
    "                                               title=site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda x: datetime.datetime.strptime(x, '%d:%m:%Y %H:%M:%S')\n",
    "df = pd.read_csv(fname_GSFC, skiprows=6, na_values=-999,\n",
    "                      parse_dates={'datetime': [0, 1]}, \n",
    "                      date_parser=dateparse, index_col=0, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GSFC = df[old_cols]\n",
    "df_GSFC.columns = new_cols\n",
    "df_GSFC['A550'] = df_GSFC['A675']*((675.0/550.0))**df_GSFC['Alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GSFC['A550'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_G = \"GSFC\"\n",
    "lat_G = df_GSFC['Lat'][0]\n",
    "lon_G = df_GSFC['Lon'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda x: datetime.datetime.strptime(x, '%d:%m:%Y %H:%M:%S')\n",
    "df = pd.read_csv(fname_Kanpur, skiprows=6, na_values=-999,\n",
    "                      parse_dates={'datetime': [0, 1]}, \n",
    "                      date_parser=dateparse, index_col=0, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Kanpur = df[old_cols]\n",
    "df_Kanpur.columns = new_cols\n",
    "df_Kanpur['A550'] = df_Kanpur['A675']*((675.0/550.0))**df_Kanpur['Alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_K = \"Kanpur\"\n",
    "lat_K = df_Kanpur['Lat'][0]\n",
    "lon_K = df_Kanpur['Lon'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Kanpur['A550'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B2010 = df_Beijing[df_Beijing.index.year == 2010]\n",
    "df_K2010 = df_Kanpur[df_Kanpur.index.year == 2010]\n",
    "df_G2010 = df_GSFC[df_GSFC.index.year == 2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axG, axB, axK) = plt.subplots(nrows=3, ncols=1, figsize=(12,8))\n",
    "\n",
    "axB.plot(df_B2010[\"DoY\"], df_B2010['A550'], label='AERONET')\n",
    "axB.set_xlabel(\"Days in 2010\")\n",
    "axB.set_title(site_B)\n",
    "axB.legend()\n",
    "\n",
    "axK.plot(df_K2010[\"DoY\"], df_K2010['A550'], label='AERONET')\n",
    "axK.set_xlabel(\"Days in 2010\")\n",
    "axK.set_title(site_K)\n",
    "axK.legend()\n",
    "\n",
    "axG.plot(df_G2010[\"DoY\"], df_G2010['A550'], label='AERONET')\n",
    "axG.set_xlabel(\"Days in 2010\")\n",
    "axG.set_title(site_G)\n",
    "axG.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
